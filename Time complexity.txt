ðŸ“˜ TIME COMPLEXITY

Time Complexity measures how the running time of an algorithm increases as the input size (n) grows.
It shows how efficiently your algorithm performs when input gets larger.

ðŸ”¹ Why It Matters
â€¢ Helps compare algorithm efficiency
â€¢ Predicts how your program will scale for big inputs
â€¢ A lower time complexity â†’ means a faster and more optimized program

ðŸ”¹ Types of Time Complexity

ðŸŸ© O(1) â€“ Constant Time
Takes same time regardless of input size.
Example:

x = arr[0]   # O(1)


âœ… Accessing an element from an array.

ðŸŸ¦ O(n) â€“ Linear Time
Time grows linearly with input size.
Example:

i = 5
while i < n:
    print("All India Coders")
    i += 1


â†’ Runs (n âˆ’ 5) times
â†’ T(n) = 3n âˆ’ 14 â†’ O(n)

ðŸ”¹ Representation Symbols

O â†’ Big O â†’ Worst Case
Î© â†’ Omega â†’ Best Case
Î˜ â†’ Theta â†’ Average Case

ðŸ§  Note:
Average time â‰  (Best + Worst) / 2
It depends on the probability of input distribution.

ðŸ”¹ Real-World Analogy
O(1) â†’ Opening a message instantly ðŸ“©
O(n) â†’ Scrolling through n messages one by one ðŸ“œ

ðŸ”¹ Key Takeaways
âœ… Time complexity shows how performance scales, not exact runtime.
âœ… Big O focuses on growth rate, not seconds.
âœ… Lower complexity â†’ faster scaling.
âœ… Predict efficiency before executing code.
âœ… Always aim for O(1) or O(log n) when possible.

âœ¨ In short:
Time complexity helps you write smarter, faster, and scalable code â€” not just working code! ðŸš€